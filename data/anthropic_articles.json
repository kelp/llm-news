{
  "timestamp": 1749798097.7229931,
  "articles": [
    {
      "title": "National Security Expert Richard Fontaine appointed to Anthropic\u2019s Long-Term Benefit Trust",
      "url": "https://www.anthropic.com/news/national-security-expert-richard-fontaine-appointed-to-anthropic-s-long-term-benefit-trust",
      "date": "2025-06-07T12:00:00+00:00",
      "source": "news",
      "summary": "Anthropic's Long-Term Benefit Trust today announced the appointment of Richard Fontaine, CEO of the Center for a New American Security, as a new member of the Trust. The Long-Term Benefit Trust (LTBT) is an independent body designed to help Anthropic achieve its public benefit mission."
    },
    {
      "title": "Claude Gov Models for U.S. National Security Customers",
      "url": "https://www.anthropic.com/news/claude-gov-models-for-u-s-national-security-customers",
      "date": "2025-06-06T12:00:00+00:00",
      "source": "news",
      "summary": "We\u2019re introducing a custom set of Claude Gov models built exclusively for U.S. national security customers. The models are already deployed by agencies at the highest level of U.S. national security, and access to these models is limited to those who operate in such classified environments."
    },
    {
      "title": "Claude in Amazon Bedrock: Approved for Use in FedRAMP High and DoD IL4/5 Workloads",
      "url": "https://www.anthropic.com/news/claude-in-amazon-bedrock-fedramp-high",
      "date": "2025-05-28T12:00:00+00:00",
      "source": "news",
      "summary": "Today, we're announcing that Claude models are approved for use in FedRAMP High and DoD Impact Level 4 and 5 workloads throughAmazon Bedrockin AWS GovCloud (US) regions."
    },
    {
      "title": "Reed Hastings appointed to Anthropic\u2019s board of directors",
      "url": "https://www.anthropic.com/news/reed-hastings",
      "date": "2025-05-28T12:00:00+00:00",
      "source": "news",
      "summary": "Today we announced that Reed Hastings, Chairman and co-founder of Netflix who served as its CEO for over 25 years, has been appointed to Anthropic's board of directors by our Long Term Benefit Trust. Hastings brings extensive experience from founding and scaling Netflix into a global entertainment powerhouse, along with his service on the boards of Facebook, Microsoft, and Bloomberg."
    },
    {
      "title": "Activating AI Safety Level 3 Protections",
      "url": "https://www.anthropic.com/news/activating-asl3-protections",
      "date": "2025-05-22T12:00:00+00:00",
      "source": "news",
      "summary": "We have activated the AI Safety Level 3 (ASL-3) Deployment and Security Standards described in Anthropic\u2019s Responsible Scaling Policy (RSP) in conjunction with launching Claude Opus 4. The ASL-3 Security Standard involves increased internal security measures that make it harder to steal model weights, while the corresponding Deployment Standard covers a narrowly targeted set of deployment measures designed to limit the risk of Claude being misused specifically for the development or acquisition of chemical, biological, radiological, and nuclear (CBRN) weapons. These measures should not lead Claude to refuse queries except on a very narrow set of topics."
    },
    {
      "title": "Introducing Claude 4",
      "url": "https://www.anthropic.com/news/claude-4",
      "date": "2025-05-22T12:00:00+00:00",
      "source": "news",
      "summary": "Today, we\u2019re introducing the next generation of Claude models:Claude Opus 4andClaude Sonnet 4, setting new standards for coding, advanced reasoning, and AI agents."
    },
    {
      "title": "New capabilities for building agents on the Anthropic API",
      "url": "https://www.anthropic.com/news/agent-capabilities-api",
      "date": "2025-05-22T12:00:00+00:00",
      "source": "news",
      "summary": "Today, we're announcing four new capabilities on the Anthropic API that enable developers to build more powerful AI agents: the code execution tool, MCP connector, Files API, and the ability to cache prompts for up to one hour."
    },
    {
      "title": "Testing our safety defenses with a new bug bounty program",
      "url": "https://www.anthropic.com/news/testing-our-safety-defenses-with-a-new-bug-bounty-program",
      "date": "2025-05-14T12:00:00+00:00",
      "source": "news",
      "summary": "Today, we're launching a new bug bounty program to stress-test our latest safety measures. Similar to the program we announced lastsummer, we're challenging researchers to find universal jailbreaks in safety classifiers that we haven't yet deployed publicly. These safeguards are part of the advanced protections we\u2019ve developed to help us meet the AI Safety Level-3 (ASL-3) Deployment Standard as part of ourResponsible Scaling Policy, the framework that governs how we develop and deploy increasingly capable AI models safely."
    },
    {
      "title": "Introducing web search on the Anthropic API",
      "url": "https://www.anthropic.com/news/web-search-api",
      "date": "2025-05-07T12:00:00+00:00",
      "source": "news",
      "summary": "Today, we're introducing web search on the Anthropic API\u2014a new tool that gives Claude access to current information from across the web. With web search enabled, developers can build Claude-powered applications and agents that deliver up-to-date insights."
    },
    {
      "title": "Introducing Anthropic's AI for Science Program",
      "url": "https://www.anthropic.com/news/ai-for-science-program",
      "date": "2025-05-05T12:00:00+00:00",
      "source": "news",
      "summary": "Today, we\u2019re launching Anthropic's AI for Science program \u2013 a new initiative designed to accelerate scientific research and discovery through access to our API. This program will provide free API credits to support researchers working on high-impact scientific projects, with a particular focus on biology and life sciences applications."
    },
    {
      "title": "Claude can now connect to your world",
      "url": "https://www.anthropic.com/news/integrations",
      "date": "2025-05-01T12:00:00+00:00",
      "source": "news",
      "summary": "Today we're announcing Integrations, a new way to connect your apps and tools to Claude. We're also expanding Claude'sResearchcapabilities with an advanced mode that searches the web, your Google Workspace, and now your Integrations too. Claude can research for up to 45 minutes before delivering a comprehensive report, complete with citations. In addition to these updates, we're making web search available globally for all Claude users on paid plans."
    },
    {
      "title": "Securing America's Compute Advantage: Anthropic\u2019s Position on the Diffusion Rule",
      "url": "https://www.anthropic.com/news/securing-america-s-compute-advantage-anthropic-s-position-on-the-diffusion-rule",
      "date": "2025-04-30T12:00:00+00:00",
      "source": "news",
      "summary": "In response to the Department of Commerce's \"Framework for Artificial Intelligence Diffusion\" interim final rule, Anthropic hassubmitted detailed analysis and recommendationsfor maintaining and strengthening export controls on advanced semiconductors. At the heart of our recommendations is a clear message: maintaining America's compute advantage through export controls is essential for national security and economic prosperity as powerful new AI systems are developed in the coming years."
    },
    {
      "title": "Introducing the Anthropic Economic Advisory Council",
      "url": "https://www.anthropic.com/news/introducing-the-anthropic-economic-advisory-council",
      "date": "2025-04-28T12:00:00+00:00",
      "source": "news",
      "summary": "Today, we\u2019re announcing the formation of the Anthropic Economic Advisory Council, a group of distinguished economists who will provide Anthropic with expert guidance on the economic implications of AI development and deployment. The Council will advise Anthropic on AI's impact on labor markets, economic growth, and broader socioeconomic systems. This work will inform the research agenda for theAnthropic Economic Index, an initiative that aims to understand AI\u2019s impact on the labor market and global economy over time."
    },
    {
      "title": "Detecting and Countering Malicious Uses of Claude: March 2025",
      "url": "https://www.anthropic.com/news/detecting-and-countering-malicious-uses-of-claude-march-2025",
      "date": "2025-04-23T12:00:00+00:00",
      "source": "news",
      "summary": "We are committed to preventing misuse of our Claude models by adversarial actors while maintaining their utility for legitimate users. While our safety measures successfully prevent many harmful outputs, threat actors continue to explore methods to circumvent these protections. We are continuously using learnings to upgrade our safeguards."
    },
    {
      "title": "Our Approach to Understanding and Addressing AI Harms",
      "url": "https://www.anthropic.com/news/our-approach-to-understanding-and-addressing-ai-harms",
      "date": "2025-04-21T12:00:00+00:00",
      "source": "news",
      "summary": "As AI capabilities rapidly advance, understanding and addressing the full spectrum of potential impacts becomes increasingly important. Today, we're sharing insights into our evolving approach to assessing and mitigating various harms that could result from our systems, ranging from catastrophic scenarios like biological threats to critical concerns like child safety, disinformation and fraud."
    },
    {
      "title": "Claude takes research to new places",
      "url": "https://www.anthropic.com/news/research",
      "date": "2025-04-15T12:00:00+00:00",
      "source": "news",
      "summary": "Earlier this year, we introducedour visionfor Claude as your collaborative partner that delivers hours of work in minutes. In line with this vision, we\u2019re continuing to expand the context that Claude has access to, as well as the kinds of outputs you can generate with Claude to support your personal and professional work."
    },
    {
      "title": "Introducing the Max Plan",
      "url": "https://www.anthropic.com/news/max-plan",
      "date": "2025-04-09T12:00:00+00:00",
      "source": "news",
      "summary": "Four major upgrades to the Max plan"
    },
    {
      "title": "Anthropic Education Report: How University Students Use Claude",
      "url": "https://www.anthropic.com/news/anthropic-education-report-how-university-students-use-claude",
      "date": "2025-04-08T12:00:00+00:00",
      "source": "news",
      "summary": "AI systems are no longer just specialized research tools: they\u2019re everyday academic companions. As AIs integrate more deeply into educational environments, we need to consider important questions about learning, assessment, and skill development. Until now, most discussions have relied on surveys and controlled experiments rather than direct evidence of how students naturally integrate AI into their academic work in real settings."
    },
    {
      "title": "Anthropic Appoints Guillaume Princen as Head of EMEA and Announces 100+ New Roles Across the Region",
      "url": "https://www.anthropic.com/news/head-of-EMEA-new-roles",
      "date": "2025-04-08T12:00:00+00:00",
      "source": "news"
    },
    {
      "title": "Introducing Anthropic's first developer conference: Code with Claude",
      "url": "https://www.anthropic.com/news/Introducing-code-with-claude",
      "date": "2025-04-03T12:00:00+00:00",
      "source": "news"
    },
    {
      "title": "Claude on Google Cloud\u2019s Vertex AI: FedRAMP High and IL2 Authorized",
      "url": "https://www.anthropic.com/news/claude-on-google-cloud-fedramp-high",
      "date": "2025-04-02T12:00:00+00:00",
      "source": "news",
      "summary": "Today, we're announcing that Claude models are now authorized for FedRAMP High and IL-2 workloads through Google Cloud's Vertex AI platform."
    },
    {
      "title": "Introducing Claude for Education",
      "url": "https://www.anthropic.com/news/introducing-claude-for-education",
      "date": "2025-04-02T12:00:00+00:00",
      "source": "news",
      "summary": "Today we're launching Claude for Education, a specialized version of Claude tailored for higher education institutions. This initiative equips universities to develop and implement AI-enabled approaches across teaching, learning, and administration\u2014ensuring educators and students play a key role in actively shaping AI's role in society."
    },
    {
      "title": "Anthropic Economic Index: Insights from Claude 3.7 Sonnet",
      "url": "https://www.anthropic.com/news/anthropic-economic-index-insights-from-claude-sonnet-3-7",
      "date": "2025-03-27T12:00:00+00:00",
      "source": "news",
      "summary": "Last month, we launched theAnthropic Economic Index\u2014a new initiative where we\u2019re regularly releasing data and research aimed at understanding AI's effects on labor markets and the economy over time."
    },
    {
      "title": "Claude can now search the web",
      "url": "https://www.anthropic.com/news/web-search",
      "date": "2025-03-20T12:00:00+00:00",
      "source": "news",
      "summary": "You can now use Claude to search the internet to provide more up-to-date and relevant responses. With web search, Claude has access to the latest events and information, boosting its accuracy on tasks that benefit from the most recent data."
    },
    {
      "title": "Anthropic\u2019s Response to Governor Newsom\u2019s AI Working Group Draft Report",
      "url": "https://www.anthropic.com/news/anthropic-s-response-to-governor-newsom-s-ai-working-group-draft-report",
      "date": "2025-03-19T12:00:00+00:00",
      "source": "news",
      "summary": "This week, the California Governor\u2019sWorking Group on AI Frontier Modelsreleased its draft report. We agree with the working group\u2019s focus on the need forobjective standardsand evidence-based policy guidance, and especially its emphasis on transparency as a means to create a well functioning AI policy environment.When done thoughtfully, transparency can be a low-cost, high-impact means of growing the evidence base around a new technology, increasing consumer trust, and causing companies to enter into positive-sum competitions with one another. We welcome greater discussion of how frontier labs should be transparent about their AI development practices and were glad to see the working group emphasize this - in particular, we appreciated the focus on the need for labs to disclose how they secure their models from theft, and how they test their models for potential national security risks.Many of the report\u2019s recommendations already reflect industry best practices which Anthropic adheres to: for example Anthropic\u2019sResponsible Scaling Policypublicly lays out how we assess our models for misuse and autonomy risks and thresholds that trigger increased safety and security measures for us. We also publicly describe the results of our safety and security testing as part of each major model release, and performthird-party testingto augment our own internal tests. Many other frontier AI companies have similar practices.In line with the report\u2019s findings, we believe governments could play a constructive role in improving transparency in the safety and security practices of frontier AI companies. At present frontier AI companies are notrequiredto have a safety and security policy (even one entirely of their choice), nor to describe it publicly, nor to publicly document the tests they run \u2013 and therefore not all companies do. We believe this could be done in alight-touch waythat does not impede innovation. As we wrote in ourrecent policy submission to the White House, we believe powerful AI systems will arrive soon - perhaps as early as the end of 2026 - so it is important we all devote effort to building a policy regime that creates greater transparency about the safety and security protocols of how AI systems are built.The Working Group has also highlighted areas where academia, civil society, and industry will need to apply more focus in the coming years - particularly on the economic impacts of AI, where Anthropic is today trying to contribute viaour Economic Index. We look forward to providing further feedback to the working group to aid and inform the work of finalizing the report. We commend the Governor for his foresight in kicking off this conversation, and we look forward to helping shape California\u2019s approach to frontier model safety."
    },
    {
      "title": "Progress from our Frontier Red Team",
      "url": "https://www.anthropic.com/news/strategic-warning-for-ai-risk-progress-and-insights-from-our-frontier-red-team",
      "date": "2025-03-19T12:00:00+00:00",
      "source": "news",
      "summary": "In this post, we are sharing what we have learned about the trajectory of potential national security risks from frontier AI models, along with some of our thoughts about challenges and best practices in evaluating these risks. The information in this post is based on work we\u2019ve carried out over the last year across four model releases. Our assessment is that AI models are displaying \u2018early warning\u2019 signs of rapid progress in key dual-use capabilities: models are approaching, and in some cases exceeding, undergraduate-level skills in cybersecurity and expert-level knowledge in some areas of biology. However, present-day models fall short of thresholds at which we consider them to generate substantially elevated risks to national security."
    },
    {
      "title": "Token-saving updates on the Anthropic API",
      "url": "https://www.anthropic.com/news/token-saving-updates",
      "date": "2025-03-13T12:00:00+00:00",
      "source": "news",
      "summary": "We've made several updates to the Anthropic API that let developers significantly increase throughput and reduce token usage with Claude 3.7 Sonnet. These include: cache-aware rate limits, simpler prompt caching, and token-efficient tool use."
    },
    {
      "title": "Get to production faster with the upgraded Anthropic Console",
      "url": "https://www.anthropic.com/news/upgraded-anthropic-console",
      "date": "2025-03-06T12:00:00+00:00",
      "source": "news",
      "summary": "We've redesigned the Anthropic Console to serve as one place to build, test, and iterate on your AI deployment with Claude and your teammates."
    },
    {
      "title": "Anthropic\u2019s Recommendations to OSTP for the U.S. AI Action Plan",
      "url": "https://www.anthropic.com/news/anthropic-s-recommendations-ostp-u-s-ai-action-plan",
      "date": "2025-03-06T12:00:00+00:00",
      "source": "news",
      "summary": "In response to the White House\u2019sRequest for Information on an AI Action Plan, Anthropichas submitted recommendationsto the Office of Science and Technology Policy (OSTP). Our recommendations are designed to better prepare America to capture the economic benefits and national security implications of powerful AI systems."
    },
    {
      "title": "Anthropic raises Series E at $61.5B post-money valuation",
      "url": "https://www.anthropic.com/news/anthropic-raises-series-e-at-usd61-5b-post-money-valuation",
      "date": "2025-03-03T12:00:00+00:00",
      "source": "news",
      "summary": "Anthropic has raised $3.5 billion at a $61.5 billion post-money valuation. The round was led by Lightspeed Venture Partners, with participation from Bessemer Venture Partners, Cisco Investments, D1 Capital Partners, Fidelity Management & Research Company, General Catalyst, Jane Street, Menlo Ventures and Salesforce Ventures, among other new and existing investors."
    },
    {
      "title": "Anthropic partners with U.S. National Labs for first 1,000 Scientist AI Jam",
      "url": "https://www.anthropic.com/news/anthropic-partners-with-u-s-national-labs-for-first-1-000-scientist-ai-jam",
      "date": "2025-02-28T12:00:00+00:00",
      "source": "news",
      "summary": "We are proud to participate in the U.S. Department of Energy\u2019s (DOE) first-ever 1,000 Scientist AI Jam, which will bring together scientists across multiple National Laboratories to evaluate frontier AI models on scientific research and national security applications. AI has the potential to dramatically accelerate scientific discovery and technological development,compressing decadesof scientific progress into just a few years by enabling a new era of invention and problem-solving that addresses humanity\u2019s greatest challenges. This week, welaunchedClaude 3.7 Sonnet, the first hybrid reasoning model on the market, which will be evaluated at the event."
    },
    {
      "title": "Introducing Anthropic's Transparency Hub",
      "url": "https://www.anthropic.com/news/introducing-anthropic-transparency-hub",
      "date": "2025-02-27T12:00:00+00:00",
      "source": "news",
      "summary": "Today, we're launching Anthropic'sTransparency Hub\u2014a detailed overview of concrete measures we're implementing to ensure our systems are safe, beneficial, and trustworthy."
    },
    {
      "title": "Claude and Alexa+",
      "url": "https://www.anthropic.com/news/claude-and-alexa-plus",
      "date": "2025-02-26T12:00:00+00:00",
      "source": "news",
      "summary": "Today, we're announcing that Claude models are helping power Alexa+. This collaboration is part of our ongoing partnership with Amazon to deliver advanced AI technology to businesses and consumers around the world."
    },
    {
      "title": "Claude 3.7 Sonnet and Claude Code",
      "url": "https://www.anthropic.com/news/claude-3-7-sonnet",
      "date": "2025-02-24T12:00:00+00:00",
      "source": "news",
      "summary": "Today, we\u2019re announcing Claude 3.7 Sonnet1, our most intelligent model to date and the first hybrid reasoning model on the market. Claude 3.7 Sonnet can produce near-instant responses or extended, step-by-step thinking that is madevisible to the user. API users also have fine-grained control overhow longthe model can think for."
    },
    {
      "title": "Anthropic signs MOU with UK Government to explore how AI can transform UK public services",
      "url": "https://www.anthropic.com/news/mou-uk-government",
      "date": "2025-02-14T12:00:00+00:00",
      "source": "news",
      "summary": "Artificial Intelligence has the potential to transform how governments operate, driving efficiency and accessibility and revolutionizing the delivery of digital services to citizens worldwide."
    },
    {
      "title": "Statement from Dario Amodei on the Paris AI Action Summit",
      "url": "https://www.anthropic.com/news/paris-ai-summit",
      "date": "2025-02-11T12:00:00+00:00",
      "source": "news",
      "summary": "We were pleased to attend the AI Action Summit in Paris, and we appreciate the French government\u2019s efforts to bring together AI companies, researchers, and policymakers from across the world. We share the goal of responsibly advancing AI for the benefit of humanity. However, greater focus and urgency is needed on several topics given the pace at which the technology is progressing. The need for democracies to keep the lead, the risks of AI, and the economic transitions that are fast approaching\u2014these should all be central features of the next summit."
    },
    {
      "title": "The Anthropic Economic Index",
      "url": "https://www.anthropic.com/news/the-anthropic-economic-index",
      "date": "2025-02-10T12:00:00+00:00",
      "source": "news",
      "summary": "In the coming years, AI systems will have a major impact on the ways people work. For that reason, we're launching theAnthropic Economic Index, an initiative aimed at understanding AI's effects on labor markets and the economy over time."
    },
    {
      "title": "Lyft to bring Claude to more than 40 million riders and over 1 million drivers",
      "url": "https://www.anthropic.com/news/lyft-announcement",
      "date": "2025-02-06T12:00:00+00:00",
      "source": "news",
      "summary": "Lyft is working with Anthropic to introduce customer-first, AI-powered Lyft products. This is to enhance the rideshare experience for its community of more than 40 million annual riders and over 1 million drivers. The work includes early research testing of new models and technology, alongside initiatives to advance Lyft's engineering capabilities."
    },
    {
      "title": "Introducing Citations on the Anthropic API",
      "url": "https://www.anthropic.com/news/introducing-citations-api",
      "date": "2025-01-23T12:00:00+00:00",
      "source": "news",
      "summary": "Today, we're launching Citations, a new API feature that lets Claude ground its answers in source documents. Claude can now provide detailed references to the exact sentences and passages it uses to generate responses, leading to more verifiable, trustworthy outputs."
    },
    {
      "title": "Anthropic achieves ISO 42001 certification for responsible AI",
      "url": "https://www.anthropic.com/news/anthropic-achieves-iso-42001-certification-for-responsible-ai",
      "date": "2025-01-13T12:00:00+00:00",
      "source": "news",
      "summary": "We are excited to announce that Anthropic has achieved accredited certification under the newISO/IEC 42001:2023 standardfor our AI management system. ISO 42001 is the first international standard outlining requirements for AI governance and helps ensure AI systems are developed and used responsibly."
    },
    {
      "title": "Elections and AI in 2024: observations and learnings",
      "url": "https://www.anthropic.com/news/elections-ai-2024",
      "date": "2024-12-12T12:00:00+00:00",
      "source": "news",
      "summary": "2024 marked the first major election cycle with widespread access to generative AI and the first major election year that Claude has been available. With concerns about generative AI's impact on election outcomes, we implemented proactive safety measures and drew upon usage analysis from our newClio tool. Across our products (Claude.ai, first party and third party API), election-related activity constituted less than 0.5% of overall use, ticking up to just over 1% of total usage in the weeks leading up to the US election. Below are insights about our election safety work and lessons learned for future elections."
    },
    {
      "title": "Claude 3.5 Haiku on AWS Trainium2 and model distillation in Amazon Bedrock",
      "url": "https://www.anthropic.com/news/trainium2-and-distillation",
      "date": "2024-12-03T12:00:00+00:00",
      "source": "news",
      "summary": "As part of our expandedcollaboration with AWS, we\u2019ve begun optimizing Claude models to run onAWS Trainium2, their most advanced AI chip."
    },
    {
      "title": "Tailor Claude\u2019s responses to your personal style",
      "url": "https://www.anthropic.com/news/styles",
      "date": "2024-11-26T12:00:00+00:00",
      "source": "news",
      "summary": "Today, we're announcing custom styles for allClaude.aiusers. Now you can tailor Claude's responses to your unique needs and workflows."
    },
    {
      "title": "Introducing the Model Context Protocol",
      "url": "https://www.anthropic.com/news/model-context-protocol",
      "date": "2024-11-25T12:00:00+00:00",
      "source": "news",
      "summary": "Today, we're open-sourcing theModel Context Protocol(MCP), a new standard for connecting AI assistants to the systems where data lives, including content repositories, business tools, and development environments. Its aim is to help frontier models produce better, more relevant responses."
    },
    {
      "title": "Powering the next generation of AI development with AWS",
      "url": "https://www.anthropic.com/news/anthropic-amazon-trainium",
      "date": "2024-11-22T12:00:00+00:00",
      "source": "news",
      "summary": "Today we\u2019re announcing an expansion of our collaboration with Amazon Web Services (AWS), deepening our work together to develop and deploy advanced AI systems. This expanded partnership includes a new $4 billion investment from Amazon and establishes AWS as our primary cloud and training partner. This will bring Amazon's total investment in Anthropic to $8 billion, while maintaining their position as a minority investor."
    },
    {
      "title": "Improve your prompts in the developer console",
      "url": "https://www.anthropic.com/news/prompt-improver",
      "date": "2024-11-14T12:00:00+00:00",
      "source": "news",
      "summary": "Today, we're introducing the ability to improve prompts and manage examples directly in theAnthropic Console. These features make it easier to leverage prompt engineering best practices and build more reliable AI applications."
    },
    {
      "title": "The case for targeted regulation",
      "url": "https://www.anthropic.com/news/the-case-for-targeted-regulation",
      "date": "2024-10-31T12:00:00+00:00",
      "source": "news",
      "summary": "Increasingly powerful AI systems have the potential toaccelerate scientific progress, unlock new medical treatments, and grow the economy. But along with the remarkable new capabilities of these AIs come significant risks.Governments should urgently take action on AI policy in the next eighteen months. The window for proactive risk prevention is closing fast."
    },
    {
      "title": "Claude 3.5 Sonnet on GitHub Copilot",
      "url": "https://www.anthropic.com/news/github-copilot",
      "date": "2024-10-29T12:00:00+00:00",
      "source": "news",
      "summary": "Starting today, the newClaude 3.5 Sonnetbegins rolling out on GitHub Copilot, enabling developers to choose Claude 3.5 Sonnet for coding\u2014directly in Visual Studio Code and GitHub.com. This integration brings Claude\u2019s coding capabilities to GitHub\u2019s community of over 100 million developers."
    },
    {
      "title": "Introducing the analysis tool in Claude.ai",
      "url": "https://www.anthropic.com/news/analysis-tool",
      "date": "2024-10-24T12:00:00+00:00",
      "source": "news",
      "summary": "We're introducing the analysis tool, a new built-in feature forClaude.aithat enables Claude to write and run JavaScript code. Claude can now process data, conduct analysis, and produce real-time insights. The analysis tool is available for all Claude.ai users infeature preview."
    },
    {
      "title": "Developing a computer use model",
      "url": "https://www.anthropic.com/news/developing-computer-use",
      "date": "2024-10-22T12:00:00+00:00",
      "source": "news",
      "summary": "Claude can now use computers. Thelatest version of Claude 3.5 Sonnetcan, when run through the appropriate software setup, follow a user\u2019s commands to move a cursor around their computer\u2019s screen, click on relevant locations, and input information via a virtual keyboard, emulating the way people interact with their own computer."
    },
    {
      "title": "Introducing computer use, a new Claude 3.5 Sonnet, and Claude 3.5 Haiku",
      "url": "https://www.anthropic.com/news/3-5-models-and-computer-use",
      "date": "2024-10-22T12:00:00+00:00",
      "source": "news",
      "summary": "Update (12/03/2024): We have revised the pricing for Claude 3.5 Haiku. The model is now priced at $0.80 MTok input / $4 MTok output."
    },
    {
      "title": "Announcing our updated Responsible Scaling Policy",
      "url": "https://www.anthropic.com/news/announcing-our-updated-responsible-scaling-policy",
      "date": "2024-10-15T12:00:00+00:00",
      "source": "news",
      "summary": "Today we are publishing a significant update to our Responsible Scaling Policy (RSP), the risk governance framework we use to mitigate potential catastrophic risks from frontier AI systems.This update introduces a more flexible and nuanced approach to assessing and managing AI risks while maintaining our commitment not to train or deploy models unless we have implemented adequate safeguards. Key improvements include new capability thresholds to indicate when we will upgrade our safeguards, refined processes for evaluating model capabilities and the adequacy of our safeguards (inspired bysafety case methodologies), and new measures for internal governance and external input. By learning from our implementation experiences and drawing on risk management practices used in other high-consequence industries, we aim to better prepare for the rapid pace of AI advancement."
    },
    {
      "title": "U.S. Elections Readiness",
      "url": "https://www.anthropic.com/news/us-elections-readiness",
      "date": "2024-10-08T12:00:00+00:00",
      "source": "news",
      "summary": "2024 marks the first United States (U.S.) election cycle where generative AI tools are widely available. Since July 2023, we havetaken concrete stepstohelp detect and mitigateagainst the potential misuse of our tools and to direct users to authoritative election information. Ahead of federal, state, and local elections in the U.S. on November 5, 2024, we are sharing a summary of our work thus far."
    },
    {
      "title": "Introducing the Message Batches API",
      "url": "https://www.anthropic.com/news/message-batches-api",
      "date": "2024-10-08T12:00:00+00:00",
      "source": "news",
      "summary": "Update: As of December 17, 2024, the Message Batches API is Generally Available on the Anthropic API. Customers using Claude in Amazon Bedrock can use batch inference. Batch predictions is also available in preview on Google Cloud\u2019s Vertex AI.We\u2019re introducing a newMessage Batches API\u2014a powerful, cost-effective way to process large volumes of queries asynchronously."
    },
    {
      "title": "Fine-tuning for Claude 3 Haiku in Amazon Bedrock is now generally available",
      "url": "https://www.anthropic.com/news/fine-tune-claude-3-haiku-ga",
      "date": "2024-09-23T12:00:00+00:00",
      "source": "news",
      "summary": "Fine-tuning for Claude 3 Haiku is now generally available inAmazon Bedrock. With fine-tuning, you can customize Claude 3 Haiku\u2014our fastest and most cost-effective model\u2014with your own data to increase model performance for specialized tasks."
    },
    {
      "title": "Introducing Contextual Retrieval",
      "url": "https://www.anthropic.com/news/contextual-retrieval",
      "date": "2024-09-19T12:00:00+00:00",
      "source": "news",
      "summary": "For an AI model to be useful in specific contexts, it often needs access to background knowledge. For example, customer support chatbots need knowledge about the specific business they're being used for, and legal analyst bots need to know about a vast array of past cases."
    },
    {
      "title": "Workspaces in the Anthropic API Console",
      "url": "https://www.anthropic.com/news/workspaces",
      "date": "2024-09-10T12:00:00+00:00",
      "source": "news",
      "summary": "We're introducing Workspaces in the Anthropic API Console to help developers efficiently manage multiple Claude deployments. Workspaces are unique environments that enable you to organize resources, streamline access controls, and set custom spend and rate limits on a more granular level."
    },
    {
      "title": "Claude for Enterprise",
      "url": "https://www.anthropic.com/news/claude-for-enterprise",
      "date": "2024-09-04T12:00:00+00:00",
      "source": "news",
      "summary": "Today, we\u2019re announcing theClaude Enterprise planto help organizations securely collaborate with Claude using internal knowledge."
    },
    {
      "title": "Salesforce teams up with Anthropic to enhance Einstein capabilities with Claude",
      "url": "https://www.anthropic.com/news/salesforce-partnership",
      "date": "2024-09-03T12:00:00+00:00",
      "source": "news",
      "summary": "Salesforce customers can now selectClaude modelsfor AI-powered Salesforce applications and experiences built with the Salesforce Platform. The latest Claude models\u2014Claude 3.5 Sonnet, Claude 3 Opus, and Claude 3 Haiku\u2014are now available to Salesforce customers using Amazon Bedrock."
    },
    {
      "title": "Artifacts are now generally available",
      "url": "https://www.anthropic.com/news/artifacts",
      "date": "2024-08-27T12:00:00+00:00",
      "source": "news",
      "summary": "Today, we\u2019re makingArtifactsavailable for allClaude.aiusers across our Free, Pro, and Team plans. And now, you can create and view Artifacts on ouriOSandAndroidapps."
    },
    {
      "title": "Prompt caching with Claude",
      "url": "https://www.anthropic.com/news/prompt-caching",
      "date": "2024-08-14T12:00:00+00:00",
      "source": "news",
      "summary": "Update: As of December 17, 2024, prompt caching is Generally Available on the Anthropic API. Prompt caching is also available in preview in Amazon Bedrock and on Google Cloud\u2019s Vertex AI.Prompt caching, which enables developers to cache frequently used context between API calls, is now available on the Anthropic API. With prompt caching, customers can provide Claude with more background knowledge and example outputs\u2014all while reducing costs by up to 90% and latency by up to 85% for long prompts. Prompt caching is available today in public beta for Claude 3.5 Sonnet, Claude 3 Opus, and Claude 3 Haiku."
    },
    {
      "title": "Expanding our model safety bug bounty program",
      "url": "https://www.anthropic.com/news/model-safety-bug-bounty",
      "date": "2024-08-08T12:00:00+00:00",
      "source": "news",
      "summary": "The rapid progression of AI model capabilities demands an equally swift advancement in safety protocols. As we work on developing the next generation of our AI safeguarding systems, we\u2019re expanding our bug bounty program to introduce a new initiative focused on finding flaws in the mitigations we use to prevent misuse of our models."
    },
    {
      "title": "Claude is now available in Brazil",
      "url": "https://www.anthropic.com/news/claude-brazil",
      "date": "2024-08-01T12:00:00+00:00",
      "source": "news",
      "summary": "Claude, Anthropic\u2019s trusted AI assistant, is now available in Brazil. Starting today, consumers and businesses in Brazil will be able to access Claude via:"
    },
    {
      "title": "Anthropic partners with Menlo Ventures to launch Anthology Fund",
      "url": "https://www.anthropic.com/news/anthropic-partners-with-menlo-ventures-to-launch-anthology-fund",
      "date": "2024-07-17T12:00:00+00:00",
      "source": "news",
      "summary": "We\u2019re launching the Anthology Fund in partnership with Menlo Ventures to accelerate the development of groundbreaking AI applications. The Fund is a $100 million initiative financed by Menlo to support startups innovating broadly with Anthropic technology."
    },
    {
      "title": "Claude Android app",
      "url": "https://www.anthropic.com/news/android-app",
      "date": "2024-07-16T12:00:00+00:00",
      "source": "news",
      "summary": "The new Claude Android app brings the power of Claude\u2014including our most powerful model, Claude 3.5 Sonnet\u2014to Android users. The app is free and accessible with all plans, including Pro and Team."
    },
    {
      "title": "Fine-tune Claude 3 Haiku in Amazon Bedrock",
      "url": "https://www.anthropic.com/news/fine-tune-claude-3-haiku",
      "date": "2024-07-11T12:00:00+00:00",
      "source": "news",
      "summary": "Update: As of November 1, 2024, fine-tuning Claude 3 Haiku in Amazon Bedrock is generally available."
    },
    {
      "title": "Evaluate prompts in the developer console",
      "url": "https://www.anthropic.com/news/evaluate-prompts",
      "date": "2024-07-09T12:00:00+00:00",
      "source": "news",
      "summary": "When building AI-powered applications, prompt quality significantly impacts results. But crafting high quality prompts is challenging, requiring deep knowledge of your application's needs and expertise with large language models. To speed up development and improve outcomes, we've streamlined this process to make it easier for users to produce high quality prompts."
    },
    {
      "title": "A new initiative for developing third-party model evaluations",
      "url": "https://www.anthropic.com/news/a-new-initiative-for-developing-third-party-model-evaluations",
      "date": "2024-07-01T12:00:00+00:00",
      "source": "news",
      "summary": "Arobust, third-party evaluation ecosystemis essential for assessing AI capabilities and risks, but the current evaluations landscape is limited. Developing high-quality, safety-relevant evaluations remains challenging, and the demand is outpacing the supply. To address this, today we're introducing a new initiative to fund evaluations developed by third-party organizations that can effectively measure advanced capabilities in AI models. Our investment in these evaluations is intended to elevate the entire field of AI safety, providing valuable tools that benefit the whole ecosystem."
    },
    {
      "title": "Expanding access to Claude for government",
      "url": "https://www.anthropic.com/news/expanding-access-to-claude-for-government",
      "date": "2024-06-26T12:00:00+00:00",
      "source": "news",
      "summary": "Anthropic's mission is to build reliable, interpretable, steerable AI systems. We have been excited to see our technology used in areas like coding, customer service, drug discovery, and medical research. We're eager to make these tools available through expanded offerings to government users. Leveraging the flexibility and security of Amazon Web Services [AWS], our AI models Claude 3 Haiku and Claude 3 Sonnet are now available in the AWS Marketplace for the US Intelligence Community [IC] and in AWS GovCloud."
    },
    {
      "title": "Collaborate with Claude on Projects",
      "url": "https://www.anthropic.com/news/projects",
      "date": "2024-06-25T12:00:00+00:00",
      "source": "news",
      "summary": "Our vision for Claude has always been to create AI systems that work alongside people and meaningfully enhance their workflows. As a step in this direction,Claude.aiPro and Team users can now organize their chats into Projects, bringing together curated sets of knowledge and chat activity in one place\u2014with the ability to make their best chats with Claude viewable by teammates. With this new functionality, Claude can enable idea generation, more strategic decision-making, and exceptional results."
    },
    {
      "title": "Claude 3.5 Sonnet",
      "url": "https://www.anthropic.com/news/claude-3-5-sonnet",
      "date": "2024-06-21T12:00:00+00:00",
      "source": "news",
      "summary": "Today, we\u2019re launching Claude 3.5 Sonnet\u2014our first release in the forthcoming Claude 3.5 model family. Claude 3.5 Sonnet raises the industry bar for intelligence, outperforming competitor models and Claude 3 Opus on a wide range of evaluations, with the speed and cost of our mid-tier model, Claude 3 Sonnet."
    },
    {
      "title": "Challenges in red teaming AI systems",
      "url": "https://www.anthropic.com/news/challenges-in-red-teaming-ai-systems",
      "date": "2024-06-12T12:00:00+00:00",
      "source": "news",
      "summary": "In this post we detail insights from a sample of red teaming approaches that we\u2019ve used to test our AI systems. Through this practice, we\u2019ve begun to gather empirical data about the appropriate tool to reach for in a given situation, and the associated benefits and challenges with each approach. We hope this post is helpful for other companies trying to red team their AI systems, policymakers curious about how red teaming works in practice, and organizations that want to red team AI technology."
    },
    {
      "title": "Testing and mitigating elections-related risks",
      "url": "https://www.anthropic.com/news/testing-and-mitigating-elections-related-risks",
      "date": "2024-06-06T12:00:00+00:00",
      "source": "news",
      "summary": "With global elections in 2024, we're often asked how we're safeguarding election integrity as AI evolves. This blog provides a snapshot of the work we've done since last summer to test our models for elections-related risks."
    },
    {
      "title": "Introducing Claude to Canada",
      "url": "https://www.anthropic.com/news/introducing-claude-to-canada",
      "date": "2024-06-05T12:00:00+00:00",
      "source": "news",
      "summary": "Claudeis now available in Canada. Starting today, people and businesses across the country will be able to access Claude via:"
    },
    {
      "title": "Claude can now use tools",
      "url": "https://www.anthropic.com/news/tool-use-ga",
      "date": "2024-05-30T12:00:00+00:00",
      "source": "news",
      "summary": "Tool use, which enables Claude to interact with external tools and APIs, is now generally available across the entire Claude 3 model family on the Anthropic Messages API, Amazon Bedrock, and Google Cloud's Vertex AI. With tool use, Claude can perform tasks, manipulate data, and provide more dynamic\u2014and accurate\u2014responses."
    },
    {
      "title": "Jay Kreps appointed to Anthropic's Board of Directors",
      "url": "https://www.anthropic.com/news/jay-kreps-appointed-to-board-of-directors",
      "date": "2024-05-29T12:00:00+00:00",
      "source": "news",
      "summary": "Today, we're announcing that Jay Kreps, co-founder and CEO of Confluent, has joined Anthropic's Board of Directors. Jay's extensive experience in building and scaling highly successful tech companies will play an important role as Anthropic prepares for the next phase of growth. His deep expertise in data infrastructure and open-source software development will be particularly valuable as we build data-driven product experiences for our growing base of enterprise customers."
    },
    {
      "title": "Golden Gate Claude",
      "url": "https://www.anthropic.com/news/golden-gate-claude",
      "date": "2024-05-23T12:00:00+00:00",
      "source": "news",
      "summary": "UPDATE: Golden Gate Claude was online for a 24-hour period as a research demo and is no longer available. If you'd like to find out more about our research on interpretability and the activation of features within Claude, please seethis postor ourfull research paper."
    },
    {
      "title": "Krishna Rao joins Anthropic as Chief Financial Officer",
      "url": "https://www.anthropic.com/news/krishna-rao-joins-anthropic",
      "date": "2024-05-21T12:00:00+00:00",
      "source": "news",
      "summary": "We\u2019re excited to announce that Krishna Rao has joined Anthropic as our Chief Financial Officer. With nearly 20 years of experience as a strategic finance leader for customer-centric, world-class brands and as an investor, Krishna will play a crucial role in shaping Anthropic's financial strategy and operations as we continue to build on our strong enterprise momentum and advance our international expansion."
    },
    {
      "title": "Generate better prompts in the developer console",
      "url": "https://www.anthropic.com/news/prompt-generator",
      "date": "2024-05-20T12:00:00+00:00",
      "source": "news",
      "summary": "You can now generate production-ready prompt templates in the Anthropic Console. Describe what you want to achieve, and Claude will use prompt engineering techniques such as chain-of-thought reasoning to create an effective, precise, and reliable prompt."
    },
    {
      "title": "Reflections on our Responsible Scaling Policy",
      "url": "https://www.anthropic.com/news/reflections-on-our-responsible-scaling-policy",
      "date": "2024-05-20T12:00:00+00:00",
      "source": "news",
      "summary": "Last summer we published our firstResponsible Scaling Policy (RSP), which focuses on addressing catastrophic safety failures and misuse of frontier models. In adopting this policy, our primary goal is to help turn high-level safety concepts into practical guidelines for fast-moving technical organizations and demonstrate their viability as possible standards. As we operationalize the policy, we expect to learn a great deal and plan to share our findings. This post shares reflections from implementing the policy so far. We are also working on an updated RSP and will share this soon."
    },
    {
      "title": "Mike Krieger joins Anthropic as Chief Product Officer",
      "url": "https://www.anthropic.com/news/mike-krieger-joins-anthropic",
      "date": "2024-05-15T12:00:00+00:00",
      "source": "news",
      "summary": "We're excited to announce that Mike Krieger has joined Anthropic as our Chief Product Officer. Mike will oversee Anthropic's product engineering, product management, and product design efforts as we work to expand our suite of enterprise applications and bring Claude to a wider audience."
    },
    {
      "title": "Claude is now available in Europe",
      "url": "https://www.anthropic.com/news/claude-europe",
      "date": "2024-05-14T12:00:00+00:00",
      "source": "news",
      "summary": "We\u2019re excited to announce thatClaude, Anthropic\u2019s trusted AI assistant, is now available for people and businesses across Europe to enhance their productivity and creativity. Starting today, they will be able to use:"
    },
    {
      "title": "Updating our Usage Policy",
      "url": "https://www.anthropic.com/news/updating-our-usage-policy",
      "date": "2024-05-10T12:00:00+00:00",
      "source": "news",
      "summary": "Today, we're updating the policies that protect our users and ensure our products and services are used responsibly. Our goal with these updates is to clarify which applications of our products are and are not allowed so our policies are clear and easy for users to understand."
    },
    {
      "title": "Introducing the Claude Team plan and iOS app",
      "url": "https://www.anthropic.com/news/team-plan-and-ios",
      "date": "2024-05-01T12:00:00+00:00",
      "source": "news",
      "summary": "Today, we\u2019re announcing two updates for Claude: a new Team plan and an iOS app."
    },
    {
      "title": "Aligning on child safety principles",
      "url": "https://www.anthropic.com/news/child-safety-principles",
      "date": "2024-04-23T12:00:00+00:00",
      "source": "news",
      "summary": "Alongside other leading AI companies, we are committed to implementing robust child safety measures in the development, deployment, and maintenance of generative AI technologies. This new initiative, led byThorn, a nonprofit dedicated to defending children from sexual abuse, andAll Tech Is Human, an organization dedicated to collectively tackling tech and society's complex problems, aims to mitigate the risks generative AI poses to children."
    },
    {
      "title": "Third-party testing as a key ingredient of AI policy",
      "url": "https://www.anthropic.com/news/third-party-testing",
      "date": "2024-03-25T12:00:00+00:00",
      "source": "news",
      "summary": "We believe that the AI sector needs effective third-party testing for frontier AI systems. Developing a testing regime and associated policy interventions based on the insights of industry, government, and academia is the best way to avoid societal harm\u2014whether deliberate or accidental\u2014from AI systems."
    },
    {
      "title": "Anthropic, AWS, and Accenture team up to build trusted solutions for enterprises",
      "url": "https://www.anthropic.com/news/accenture-aws-anthropic",
      "date": "2024-03-20T12:00:00+00:00",
      "source": "news",
      "summary": "Today weannounced a collaborationwith Amazon Web Services (AWS) and Accenture. All three organizations are providing key resources to take generative AI ideas from concept to production, especially those in regulated sectors where accuracy, reliability and data security are paramount. Enterprises will be able to deploy models to address their specific needs, while keeping their data private and secure."
    },
    {
      "title": "Claude 3 models on Vertex AI",
      "url": "https://www.anthropic.com/news/google-vertex-general-availability",
      "date": "2024-03-19T12:00:00+00:00",
      "source": "news",
      "summary": "Claude 3 Haiku and Claude 3 Sonnet are now generally available on Google Cloud\u2019s Vertex AI platform. Enterprises can use our state-of-the-art models that optimize intelligence, speed, and cost with Google Cloud's robust infrastructure and tools. This collaboration enables businesses to quickly prototype and scale generative AI solutions with enterprise-grade data privacy and security. The benefits for Google Cloud customers include the ability to keep their data within their existing cloud environment, simplify data governance, reduce operational costs and complexities, and more easily manage access permissions."
    },
    {
      "title": "Claude 3 Haiku: our fastest model yet",
      "url": "https://www.anthropic.com/news/claude-3-haiku",
      "date": "2024-03-13T12:00:00+00:00",
      "source": "news",
      "summary": "Today we\u2019re releasing Claude 3 Haiku, the fastest and most affordable model in its intelligence class. With state-of-the-art vision capabilities and strong performance on industry benchmarks, Haiku is a versatile solution for a wide range of enterprise applications. The model is now available alongside Sonnet and Opus in the Claude API and on claude.ai for our Claude Pro subscribers."
    },
    {
      "title": "Introducing the next generation of Claude",
      "url": "https://www.anthropic.com/news/claude-3-family",
      "date": "2024-03-04T12:00:00+00:00",
      "source": "news",
      "summary": "Today, we're announcing the Claude 3 model family, which sets new industry benchmarks across a wide range of cognitive tasks. The family includes three state-of-the-art models in ascending order of capability: Claude 3 Haiku, Claude 3 Sonnet, and Claude 3 Opus. Each successive model offers increasingly powerful performance, allowing users to select the optimal balance of intelligence, speed, andcostfor their specific application."
    },
    {
      "title": "Prompt engineering for business performance",
      "url": "https://www.anthropic.com/news/prompt-engineering-for-business-performance",
      "date": "2024-02-29T12:00:00+00:00",
      "source": "news",
      "summary": "As businesses build with generative AI models, crafting effective prompts has become critical for producing high-quality outputs. This post explains basic prompt engineering techniques that help our customers get the most value from Claude. With the right prompts, businesses can tap into the full potential of AI to increase productivity across a wide range of tasks."
    },
    {
      "title": "Preparing for global elections in 2024",
      "url": "https://www.anthropic.com/news/preparing-for-global-elections-in-2024",
      "date": "2024-02-16T12:00:00+00:00",
      "source": "news",
      "summary": "Over half of the world\u2019s population will vote this year with high profile elections taking place around the world, including in the United States, India, Europe, and many other countries and regions. At Anthropic, we\u2019ve been preparing since last July for how our AI systems might be used during elections. In this post, we\u2019ll discuss some of the specific steps we\u2019ve taken to help us detect and mitigate potential misuse of our AI tools in political contexts."
    },
    {
      "title": "Expanded legal protections and improvements to our API",
      "url": "https://www.anthropic.com/news/expanded-legal-protections-api-improvements",
      "date": "2023-12-19T12:00:00+00:00",
      "source": "news",
      "summary": "We are introducing new, simplified Commercial Terms of Service with an expanded copyright indemnity, as well as an improved developer experience with our beta Messages API. Customers will now enjoy increased protection and peace of mind as they build with Claude, as well as a more streamlined API that is easier to use."
    },
    {
      "title": "Long context prompting for Claude 2.1",
      "url": "https://www.anthropic.com/news/claude-2-1-prompting",
      "date": "2023-12-06T12:00:00+00:00",
      "source": "news",
      "summary": "We recently launchedClaude 2.1, our state-of-the-art model offering a 200K token context window - the equivalent of around 500 pages of information. Claude 2.1 excels at real-world retrieval tasks across longer contexts.Claude 2.1 was trained using large amounts of feedback on long document tasks that our users find valuable, like summarizing an S-1 length document. This data included real tasks performed on real documents, with Claude being trained to make fewer mistakes and to avoid expressing unsupported claims.Being trained on real-world, complex retrieval tasks is why Claude 2.1 shows a 30% reduction in incorrect answers compared with Claude 2.0, and a 3-4x lower rate of mistakenly stating that a document supports a claim when it does not.Additionally, Claude's memory is improved over these very long contexts:"
    },
    {
      "title": "Introducing Claude 2.1",
      "url": "https://www.anthropic.com/news/claude-2-1",
      "date": "2023-11-21T12:00:00+00:00",
      "source": "news",
      "summary": "Our latest model, Claude 2.1, is now available over API in our Console and is powering ourclaude.aichat experience. Claude 2.1 delivers advancements in key capabilities for enterprises\u2014including an industry-leading 200K token context window, significant reductions in rates of model hallucination, system prompts and our new beta feature: tool use. We are also updating ourpricingto improve cost efficiency for our customers across models.200K Context WindowSince our launch earlier this year, Claude has been used by millions of people for a wide range of applications\u2014from translating academic papers to drafting business plans and analyzing complex contracts. In discussions with our users, they\u2019ve asked for larger context windows and more accurate outputs when working with long documents.In response, we\u2019re doubling the amount of information you can relay to Claude with a limit of 200,000 tokens, translating to roughly 150,000 words, or over 500 pages of material. Our users can now upload technical documentation like entire codebases, financial statements like S-1s, or even long literary works like The Iliad or The Odyssey. By being able to talk to large bodies of content or data, Claude can summarize, perform Q&A, forecast trends, compare and contrast multiple documents, and much more."
    },
    {
      "title": "Thoughts on the US Executive Order, G7 Code of Conduct, and Bletchley Park Summit",
      "url": "https://www.anthropic.com/news/policy-recap-q4-2023",
      "date": "2023-11-05T12:00:00+00:00",
      "source": "news",
      "summary": "Three major events in AI policy happened in the last week: the US government issued a wide-rangingExecutive Order on AI, the G7 produced anInternational Code of Conduct, and the UK government held a first-of-its-kind summit on AI safety at Bletchley Park which produced theBletchley Declaration. In this post, we briefly summarize each of these events and what we believe they mean for AI policy."
    },
    {
      "title": "Dario Amodei\u2019s prepared remarks from the AI Safety Summit on Anthropic\u2019s Responsible Scaling Policy",
      "url": "https://www.anthropic.com/news/uk-ai-safety-summit",
      "date": "2023-11-01T12:00:00+00:00",
      "source": "news",
      "summary": "Before I get into Anthropic\u2019sResponsible Scaling Policy (RSP), it\u2019s worth explaining some of the unique challenges around measuring AI risks that led us to develop our RSP. The most important thing to understand about AI is how quickly it is moving. A few years ago, AI systems could barely string together a coherent sentence. Today they can pass medical exams, write poetry, and tell jokes. This rapid progress is ultimately driven by the amount of available computation, which is growing by 8x per year and is unlikely to slow down in the next few years. Thegeneraltrend of rapid improvement is predictable, however, it is actually very difficult to predict when AI will acquirespecificskills or knowledge. This unfortunately includes dangerous skills, such as the ability to construct biological weapons1. We are thus facing a number of potential AI-related threats which, although relatively limited given today\u2019s systems, are likely to become very serious at some unknown point in the near future. This is very different from most other industries: imagine if each new model of car had some chance of spontaneously sprouting a new (and dangerous) power, like the ability to fire a rocket boost or accelerate to supersonic speeds.We need both a way to frequently monitor these emerging risks, and a protocol for responding appropriately when they occur. Responsible scaling policies\u2014initially suggested by the Alignment Research Center\u2014attempt to meet this need. Anthropic published its RSP in September, and was the first major AI company to do so. It has two major components:"
    },
    {
      "title": "Claude on Amazon Bedrock now available to every AWS customer",
      "url": "https://www.anthropic.com/news/amazon-bedrock-general-availability",
      "date": "2023-09-28T12:00:00+00:00",
      "source": "news",
      "summary": "Claude is now generally available onAmazon Bedrock, the fully managed service that provides Amazon Web Services (AWS) customers with secure cloud access to foundation models and tools for building generative AI applications.This means that every AWS customer can now build with Claude, and will soon gain access to an exciting roadmap of new experiences - includingAgents for Amazon Bedrock, which our team has been instrumental in developing.Currently available in preview, Agents for Amazon Bedrock can orchestrate and perform API calls using the popularAWS Lambdafunctions. Through this feature, Claude can take on a more expanded role as an agent to understand user requests, break down complex tasks into multiple steps, carry on conversations to collect additional details, look up information, and take actions to fulfill requests. For example, an e-commerce app that offers a chat assistant built with Claude can go beyond just querying product inventory \u2013 it can actually help customers update their orders, make exchanges, and look up relevant user manuals.We also recently shared that we\u2019ll offersecure customization and fine-tuningof Claude models through the service. This technique optimizes Claude\u2019s performance with AWS customers\u2019 expert knowledge and proprietary data to drive more relevant results, while limiting the potential for harmful outputs.The general availability of Claude on Amazon Bedrock advances our work in helping enterprises responsibly integrate transformative AI. In the coming months, we\u2019ll be announcing even more application layer solutions to help organizations get the most value out of Claude.Spotlight: How Bridgewater Associates is augmenting analyst productivity with Claude"
    },
    {
      "title": "Expanding access to safer AI with Amazon",
      "url": "https://www.anthropic.com/news/anthropic-amazon",
      "date": "2023-09-25T12:00:00+00:00",
      "source": "news",
      "summary": "Today, we\u2019re announcing that Amazon will invest up to $4 billion in Anthropic. The agreement is part of a broader collaboration to develop the most reliable and high-performing foundation models in the industry. Our frontier safety research and products, together with Amazon Web Services\u2019 (AWS) expertise in running secure, reliable infrastructure, will make Anthropic\u2019s safe and steerable AI widely accessible to AWS customers.AWS will become Anthropic\u2019s primary cloud provider for mission critical workloads, providing our team with access to leading compute infrastructure in the form of AWS Trainium and Inferentia chips, which will be used in addition to existing solutions for model training and deployment. Together, we\u2019ll combine our respective expertise to collaborate on the development of future Trainium and Inferentia technology.Based on significant AWS customer demand for Claude, we\u2019re also expanding our support ofAmazon Bedrock. This will include secure model customization and fine-tuning on the service to enable enterprises to optimize Claude\u2019s performance with their expert knowledge, while limiting the potential for harmful outcomes.Amazon developers and engineers will be able to build on top of our state-of-the-art models via Amazon Bedrock. This will enable them to incorporate generative AI capabilities into their work, enhance existing applications, and create net-new customer experiences across Amazon\u2019s businesses.Organizations\u00a0will be able to useClaude 2for a wide range of tasks, from sophisticated dialogue and creative content generation to complex reasoning and detailed instruction. Our industry-leading 100,000 token context window will help them securely process extensive amounts of information\u2014including technical, domain-specific documents for use cases across finance, legal, coding, and more.Enterprises across many industries are already building with Anthropic models on Amazon Bedrock.LexisNexis Legal & Professional, a leading global provider of information and analytics, is using a custom, fine-tuned Claude 2 model to deliver conversational search, insightful summarization, and intelligent legal drafting capabilities via the company\u2019s new Lexis+ AI solution. Premier asset management firmBridgewater Associatesis developing an investment analyst assistant powered by Claude 2 to generate elaborate charts, compute financial indicators, and create summaries of the results.Lonely Planet, a renowned travel publisher, reduced its itinerary generation costs by almost 80 percent after deploying Claude 2; synthesizing its decades of travel content to deliver cohesive, highly accurate travel recommendations.Anthropic and Amazon are both committed to the safe training and deployment of advanced foundation models. Amazon is an industry leader in cloud security and, as part of this agreement, is committed to promoting and implementing safety best practices on Amazon Bedrock to ensure the responsible use of our products and services. Both companies are actively engaged across a number of organizations to promote the responsible development and deployment of AI technologies, including the Global Partnership on AI (GPAI), the Partnership on AI (PAI), and the National Institute of Standards and Technology (NIST). Most recently, in July, both Amazon and Anthropic independently supported a set of voluntary safety commitments led by the White House to ensure that the future of transformative AI is guided by safety, security, and trust.As part of the investment, Amazon will take a minority stake in Anthropic. Our corporate governance structure remains unchanged, with theLong Term Benefit Trustcontinuing to guide Anthropic in accordance with ourResponsible Scaling Policy. As outlined in this policy, we will conduct pre-deployment tests of new models to help us manage the risks of increasingly capable AI systems.Training state-of-the-art models requires extensive resources including compute power and\u00a0research programs. Amazon\u2019s investment and supply of AWS Trainium and Inferentia technology will ensure we\u2019re equipped to continue advancing the frontier of AI safety and research. We look forward to working closely with Amazon to responsibly scale adoption of Claude and deliver safe AI cloud technologies to organizations around the world."
    },
    {
      "title": "Prompt engineering for Claude's long context window",
      "url": "https://www.anthropic.com/news/prompting-long-context",
      "date": "2023-09-23T12:00:00+00:00",
      "source": "news",
      "summary": "Claude\u2019s100,000 token long context windowenables the model to operate over hundreds of pages of technical documentation, or even anentire book. As we continue to scale the Claude API, we\u2019re seeing increased demand for prompting guidance on how to maximize Claude\u2019s potential. Today, we\u2019re pleased to share a quantitative case study on two techniques that can improve Claude\u2019s recall over long contexts:"
    },
    {
      "title": "Anthropic's Responsible Scaling Policy",
      "url": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy",
      "date": "2023-09-19T12:00:00+00:00",
      "source": "news",
      "summary": "Today, we\u2019re publishing ourResponsible Scaling Policy (RSP)\u2013 a series of technical and organizational protocols that we\u2019re adopting to help us manage the risks of developing increasingly capable AI systems.As AI models become more capable, we believe that they will create major economic and social value, but will also present increasingly severe risks. Our RSP focuses on catastrophic risks \u2013 those where an AI model directly causes large scale devastation. Such risks can come from deliberate misuse of models (for example use by terrorists or state actors to create bioweapons) or from models that cause destruction by acting autonomously in ways contrary to the intent of their designers."
    },
    {
      "title": "The Long-Term Benefit Trust",
      "url": "https://www.anthropic.com/news/the-long-term-benefit-trust",
      "date": "2023-09-19T12:00:00+00:00",
      "source": "news",
      "summary": "Today we are sharing more details about our new governance structure called theLong-Term Benefit Trust (LTBT), which we have been developing since the birth of Anthropic. The LTBT is our attempt to fine-tune our corporate governance to address the unique challenges and long-term opportunities we believetransformative AI will present."
    },
    {
      "title": "Anthropic partners with BCG",
      "url": "https://www.anthropic.com/news/anthropic-bcg",
      "date": "2023-09-14T12:00:00+00:00",
      "source": "news",
      "summary": "We\u2019re pleased to announce our new collaboration with Boston Consulting Group (BCG) to bring Claude to more enterprises. BCG customers around the world will get direct access to our AI assistant to power their strategic AI offerings and deploy safer, more reliable AI solutions.Our work towards creating helpful, honest and harmless systems with techniques likeConstitutional AIaligns with BCG\u2019s focus onresponsible AI. Through this collaboration, BCG will advise their customers on strategic applications of AI and help them deploy Anthropic models includingClaude 2to deliver business results. Use cases involving Claude span knowledge management, market research, fraud detection, demand forecasting, report generation, business analysis and more.Anthropic and BCG have already partnered to help organizations understand the force-multiplying impact of generative AI, most recently at the United Nations. In addition to working together to bring AI to new organizations, BCG has partnered with Anthropic to use Claude within its own teams. We're excited to see how Claude will provide BCG with the ability to synthesize research effectively, analyze data quickly, and drive inspired insights to clients.\u201cThe large enterprises I talk with are focused on harnessing value and bottom line impact from AI, and doing that in the most effective and ethical way possible. Aligning these two\u00a0aspects of AI is a challenge and the price for getting it wrong can be immense, both financially and in reputational harm. Our new collaboration with Anthropic will help deliver that alignment on ethics and effective GenAI,\u201d says Sylvain Duranton, global leader of BCG X, BCG\u2019s tech build and design unit. \u201cTogether, we aim to set a new standard for responsible enterprise AI and promote a safety race to the top for AI to be deployed ethically.\u201dWe\u2019re extending a warm welcome to BCG and its customers\u2014and look forward to working with them to deploy innovative applications of generative AI safely and responsibly."
    },
    {
      "title": "Introducing Claude Pro",
      "url": "https://www.anthropic.com/news/claude-pro",
      "date": "2023-09-07T12:00:00+00:00",
      "source": "news",
      "summary": "Today, we\u2019re introducing a paid plan for ourClaude.aichat experience, currently available in the US and UK.Since launching in July, users tell us they\u2019ve chosen Claude.ai as their day-to-day AI assistant for its longer context windows, faster outputs, complex reasoning capabilities, and more.\u00a0Many also shared that they would value more file uploads and conversations over longer periods.WithClaude Pro, subscribers can now gain5x more usageof our latest model, Claude 2, for a monthly price of $20 (US) or \u00a318 (UK).This means you can level up your productivity across a range of tasks, including summarizing research papers, querying contracts, and iterating further on coding projects\u2014like this recentdemoof building an interactive map."
    },
    {
      "title": "Claude 2 on Amazon Bedrock",
      "url": "https://www.anthropic.com/news/claude-2-amazon-bedrock",
      "date": "2023-08-23T12:00:00+00:00",
      "source": "news",
      "summary": "We\u2019re excited that Claude 2 is now available to customers on Amazon Bedrock."
    },
    {
      "title": "SKT Partnership Announcement",
      "url": "https://www.anthropic.com/news/skt-partnership-announcement",
      "date": "2023-08-15T12:00:00+00:00",
      "source": "news",
      "summary": "We are pleased to announce that SK Telecom (\"SKT\"), the largest mobile operator in Korea rapidly integrating AI into its business, has become a commercial partner with Anthropic as well as a strategic investor."
    },
    {
      "title": "Releasing Claude Instant 1.2",
      "url": "https://www.anthropic.com/news/releasing-claude-instant-1-2",
      "date": "2023-08-09T12:00:00+00:00",
      "source": "news",
      "summary": "Businesses working with Claude can now access our latest version of Claude Instant, version 1.2, availablethrough our API.\u00a0Claude Instant is our faster, lower-priced yet still very capable model, which can handle a range of tasks including casual dialogue, text analysis, summarization, and document comprehension.Claude Instant 1.2 incorporates the strengths of our latest\u00a0model Claude 2\u00a0in real-world use cases and shows significant gains in key areas like math, coding, reasoning, and safety. It generates longer, more structured responses and follows formatting instructions better. Instant 1.2 also shows improvements in quote extraction, multilingual capabilities, and question answering."
    },
    {
      "title": "Frontier Threats Red Teaming for AI Safety",
      "url": "https://www.anthropic.com/news/frontier-threats-red-teaming-for-ai-safety",
      "date": "2023-07-26T12:00:00+00:00",
      "source": "news",
      "summary": "\u201cRed teaming,\u201d or adversarial testing, is a recognized technique to measure and increase the safety and security of systems. Whileprevious Anthropic researchreported methods and results for red teaming using crowdworkers, for some time, AI researchers have noted that AI models could eventually obtain capabilities in areas relevant to national security. For example, researchers havecalledtomeasureandmonitorthese risks, and havewrittenpaperswith evidence of risks. Anthropic CEO Dario Amodei also highlighted this topic\u00a0inrecent Senate testimony. With that context, we were pleased to advocate for and join in commitments announced at the White House on July 21 that included \u201cinternal and external security testing of [our] AI systems\u201d to guard against \u201csome of the most significant sources of AI risks, such as biosecurity and cybersecurity.\u201d However, red teaming in these specialized areas requires intensive investments of time and subject matter expertise.In this post, we share our approach to \u201cfrontier threats red teaming,\u201d high level findings from a project we conducted on biological risks as a test project, lessons learned, and our future plans in this area.Our goal in this work is to evaluate a baseline of risk, and to create a repeatable way to perform frontier threats red teaming across many topic areas. With respect to biology, while the details of our findings are highly sensitive, we believe it\u2019s important to share our takeaways from this work. In summary, working withexperts, we found that models might soon present risks to national security, if unmitigated. However, we also found that there are mitigations to substantially reduce these risks.We are nowscaling up this workin order to reliably identify risks and build mitigations. We believe that improving frontier threats red teaming will have immediate benefits and contribute tolong-term AI safety. We have been sharing our findings with government, labs, and other stakeholders, and we\u2019d like to see more independent groups doing this work."
    },
    {
      "title": "Frontier Model Security",
      "url": "https://www.anthropic.com/news/frontier-model-security",
      "date": "2023-07-25T12:00:00+00:00",
      "source": "news",
      "summary": "As the capabilities of frontier artificial intelligence models continue to increase rapidly, ensuring the security of these systems has become a critical priority. In our previous posts, we\u2019ve focused on Anthropic\u2019sapproach to safety, and Claude\u2019s capabilities and applications. In this post, we are sharing some of the steps we are taking to ensure our models are developed securely. We hope to advance public discussion about how all labs can deploy top models securely, as well as share recommendations for government regulatory approaches that encourage adoption of strong cybersecurity practices. Below we discuss some of our recommendations for cybersecurity best practices, which Anthropic itself is in the process of implementing."
    },
    {
      "title": "Claude 2",
      "url": "https://www.anthropic.com/news/claude-2",
      "date": "2023-07-11T12:00:00+00:00",
      "source": "news",
      "summary": "We are pleased to announceClaude 2, our new model. Claude 2 has improved performance, longer responses, and can be accessed via API as well as a new public-facing beta website,claude.ai. We have heard from our users that Claude is easy to converse with, clearly explains its thinking, is less likely to produce harmful outputs, and has a longer memory. We have made improvements from our previous models on coding, math, and reasoning. For example, our latest model scored76.5%on the multiple choice section of the Bar exam, up from 73.0% with Claude 1.3. When compared to college students applying to graduate school, Claude 2 scores above the 90th percentile on the GRE reading and writing exams, and similarly to the median applicant on quantitative reasoning."
    },
    {
      "title": "Charting a Path to AI Accountability",
      "url": "https://www.anthropic.com/news/charting-a-path-to-ai-accountability",
      "date": "2023-06-13T12:00:00+00:00",
      "source": "news",
      "summary": "This week, Anthropic submitteda responseto the National Telecommunications and Information Administration\u2019s (NTIA)Request for Comment on AI Accountability. Today, we want to share our recommendations as they capture some of Anthropic\u2019s core AI policy proposals."
    },
    {
      "title": "Anthropic Raises $450 Million in Series C Funding to Scale Reliable AI Products",
      "url": "https://www.anthropic.com/news/anthropic-series-c",
      "date": "2023-05-23T12:00:00+00:00",
      "source": "news",
      "summary": "We are pleased to announce that we have raised $450 million in Series C funding led by Spark Capital with participation from Google, Salesforce Ventures, Sound Ventures, Zoom Ventures, and others. The funding will support our continued work developing helpful, harmless, and honest AI systems\u2014including Claude, an AI assistant that can perform a wide variety of conversational and text processing tasks."
    },
    {
      "title": "Zoom Partnership and Investment in Anthropic",
      "url": "https://www.anthropic.com/news/zoom-partnership-and-investment",
      "date": "2023-05-16T12:00:00+00:00",
      "source": "news",
      "summary": "We are announcing a new partnership with Zoom, a leader in enterprise collaboration and communication solutions. Zoom will use Claude, our AI assistant built with Constitutional AI, to build customer-facing AI products focused on reliability, productivity, and safety."
    },
    {
      "title": "Introducing 100K Context Windows",
      "url": "https://www.anthropic.com/news/100k-context-windows",
      "date": "2023-05-11T12:00:00+00:00",
      "source": "news",
      "summary": "We\u2019ve expanded Claude\u2019s context window from 9K to 100K tokens, corresponding to around 75,000 words! This means businesses can now submithundreds of pagesof materials for Claude to digest and analyze, and conversations with Claude can go on for hours or even days."
    },
    {
      "title": "Claude\u2019s Constitution",
      "url": "https://www.anthropic.com/news/claudes-constitution",
      "date": "2023-05-09T12:00:00+00:00",
      "source": "news",
      "summary": "How does a language model decide which questions it will engage with and which it deems inappropriate? Why will it encourage some actions and discourage others? What \u201cvalues\u201d might a language model have?These are all questions people grapple with. Our recently published research on \u201cConstitutional AI\u201d provides one answer by giving language models explicit values determined by a constitution, rather than values determined implicitly via large-scale human feedback. This isn\u2019t a perfect approach, but it does make the values of the AI system easier to understand and easier to adjust as needed.Since launchingClaude, our AI assistant trained with Constitutional AI, we've heard more questions about Constitutional AI and how it contributes to making Claude safer and more helpful. In this post, we explain what constitutional AI is, what the values in Claude\u2019s constitution are, and how we chose them.If you just want to skip to the principles, scroll down to the last section which is entitled \u201cThe Principles in Full.\u201d"
    },
    {
      "title": "Partnering with Scale to Bring Generative AI to Enterprises",
      "url": "https://www.anthropic.com/news/partnering-with-scale",
      "date": "2023-04-26T12:00:00+00:00",
      "source": "news",
      "summary": "We are pleased to announce our partnership withScale, a leading platform for building, deploying and managing Generative AI applications. Scale customers will now be able to use Claude, our conversational AI assistant based on research into training helpful, honest, and harmless systems."
    },
    {
      "title": "An AI Policy Tool for Today: Ambitiously Invest in NIST",
      "url": "https://www.anthropic.com/news/an-ai-policy-tool-for-today-ambitiously-invest-in-nist",
      "date": "2023-04-20T12:00:00+00:00",
      "source": "news",
      "summary": "We believe that sensible artificial intelligence (AI) policy requires, among other things, the ability to accurately describe and quantify the capabilities and risks of AI systems. This ability is both an enabler and a prerequisite to effective regulation, as measurement tools allow us to objectively assess systems and ensure they meet appropriate safety thresholds. In this post, we propose a policy intervention for how to do this: ambitiously fund the National Institute of Standards and Technology (NIST) to support its AI measurement and standards efforts.We were heartened by the bipartisan support for maintaining American leadership in the development of critical technologies, as expressed during the April 18budget hearingon the 2024 Request for the Department of Commerce (and by extension, NIST). We think one of the best ways to channel that support is through an increase in federal funding for NIST so that it is well placed to carry out its work promoting safe technological innovation.In this post, we give an overview of why we think this, and we also share a policy proposal for what an ambitious funding program for NIST could look like in practice. This proposal is readily actionable and builds on a solid foundation of existing work at the agency; we view it as a complement to a suite of policy levers for stronger AI governance."
    },
    {
      "title": "Claude, now in Slack",
      "url": "https://www.anthropic.com/news/claude-now-in-slack",
      "date": "2023-03-30T12:00:00+00:00",
      "source": "news",
      "summary": "Today we are releasing the newClaude App for Slack, now in beta. Built on top of Slack\u2019s platform, the app can summarize threads, answer questions, and more. Now any company has the chance to have a \u201cvirtual teammate\u201d who can help make work more fun and productive."
    },
    {
      "title": "Introducing Claude",
      "url": "https://www.anthropic.com/news/introducing-claude",
      "date": "2023-03-14T12:00:00+00:00",
      "source": "news",
      "summary": "After working for the past few months with key partners like Notion, Quora, and DuckDuckGo in a closed alpha, we\u2019ve been able to carefully test out our systems in the wild, and areready to offer Claude more broadlyso it can power crucial, cutting-edge use cases at scale."
    },
    {
      "title": "Core Views on AI Safety: When, Why, What, and How",
      "url": "https://www.anthropic.com/news/core-views-on-ai-safety",
      "date": "2023-03-08T12:00:00+00:00",
      "source": "news",
      "summary": "We founded Anthropic because we believe the impact of AI might be comparable to that of the industrial and scientific revolutions, but we aren\u2019t confident it will go well. And we also believe this level of impact could start to arrive soon \u2013 perhaps in the coming decade."
    },
    {
      "title": "Anthropic Partners with Google Cloud",
      "url": "https://www.anthropic.com/news/anthropic-partners-with-google-cloud",
      "date": "2023-02-03T12:00:00+00:00",
      "source": "news",
      "summary": "Anthropic, an AI safety and research company, hasselectedGoogle Cloud as its cloud provider. The partnership is designed so that the companies can co-develop AI computing systems; Anthropic will leverage Google Cloud's cutting-edge GPU and TPU clusters to train, scale, and deploy its AI systems.\u201cWe're partnering with Google Cloud to support the next phase of Anthropic, where we're going to deploy our AI systems to a larger set of people,\u201d said Anthropic CEO Dario Amodei. \u201cThis partnership gives us the cloud infrastructure performance and scale we need.\u201dAnthropic is focused on developing and deploying Claude, an AI assistant based on the company's research into building safe, steerable AI. Anthropic has created safety techniques likeConstitutional AIto create AI technologies that are easier to rely on and understand.\u201cWe are eager to use the Google Cloud infrastructure to build reliable, interpretable, and steerable AI systems. This partnership with Google Cloud will let us build a more robust AI platform,\u201d said Dario Amodei."
    },
    {
      "title": "Anthropic Raises Series B to Build Steerable, Interpretable, Robust AI Systems",
      "url": "https://www.anthropic.com/news/anthropic-raises-series-b-to-build-safe-reliable-ai",
      "date": "2022-04-29T12:00:00+00:00",
      "source": "news",
      "summary": "Anthropic, an AI safety and research company, has raised $580 million in a Series B. The financing will help Anthropic build large-scale experimental infrastructure to explore and improve the safety properties of computationally intensive AI models.Since its founding at the beginning of 2021, Anthropic has conducted research into making systems that are more steerable, robust, and interpretable. On interpretability, it has made progress in mathematicallyreverse engineering the behavior of small language modelsand begun to understand the source ofpattern-matching behavior in large language models. On steerability and robustness, it has developedbaseline techniques to make large language models more \u201chelpful and harmless\u201d, and followed this up withreinforcement learning to further improve these properties, as well as releasing a dataset to help other research labs train models that are morealigned with human preferences. It has also released an analysis ofsudden changes in performance in large language models and the societal impacts of this phenomenon, which demonstrates the need for studying safety issues at scale.The purpose of this research is to develop the technical components necessary to build large-scale models which have better implicit safeguards and require less after-training interventions, as well as to develop the tools necessary to further look inside these models to be confident that the safeguards actually work. The company is also building out teams and partnerships dedicated to exploring the policy and societal impacts of these models.\u201cWith this fundraise, we\u2019re going to explore the predictable scaling properties of machine learning systems, while closely examining the unpredictable ways in which capabilities and safety issues can emerge at-scale,\u201d said Anthropic co-founder and CEO Dario Amodei. \u201cWe\u2019ve made strong initial progress on understanding and steering the behavior of AI systems, and are gradually assembling the pieces needed to make usable, integrated AI systems that benefit society.\u201dAnthropic is now a growing team of around 40 people based in a plant-filled office in San Francisco, California, with plans to expand further this year. \u201cNow that we\u2019ve built out the organization, we\u2019re focusing on ensuring Anthropic has the culture and governance to continue to responsibly explore and develop safe AI systems as we scale,\u201d said Anthropic co-founder and President Daniela Amodei. \u201cWe\u2019re excited about what\u2019s ahead, and grateful to all be working together.\u201dThe Series B follows the company raising $124 million in a Series A round in 2021. The Series B round was led by Sam Bankman-Fried, CEO of FTX. The round also included participation from Caroline Ellison, Jim McClave, Nishad Singh, Jaan Tallinn, and the Center for Emerging Risk Research (CERR)."
    },
    {
      "title": "Anthropic raises $124 million to build more reliable, general AI systems",
      "url": "https://www.anthropic.com/news/anthropic-raises-124-million-to-build-more-reliable-general-ai-systems",
      "date": "2021-05-28T12:00:00+00:00",
      "source": "news",
      "summary": "Anthropic, an AI safety and research company, has raised $124 million in a Series A. The financing round will support Anthropic in executing against its research roadmap and building prototypes of reliable and steerable AI systems.The company is led by siblings Dario Amodei (CEO) and Daniela Amodei (President). The Anthropic team has previously conducted research intoGPT-3,Circuit-Based Interpretability,Multimodal Neurons,Scaling Laws,AI & Compute,Concrete Problems in AI Safety, andLearning from Human Preferences. Anthropic will use the funding for computationally-intensive research to develop large-scale AI systems that are steerable, interpretable, and robust.\u201cAnthropic\u2019s goal is to make the fundamental research advances that will let us build more capable, general, and reliable AI systems, then deploy these systems in a way that benefits people. We\u2019re thrilled to be working with investors that support us in this mission and expect to concentrate on research in the immediate term,\u201d said Anthropic CEO Dario Amodei.Anthropic will focus on research into increasing the safety of AI systems; specifically, the company is focusing on increasing the reliability of large-scale AI models, developing the techniques and tools to make them more interpretable, and building ways to more tightly integrate human feedback into the development and deployment of these systems.The Series A round was led by Jaan Tallinn, technology investor and co-founder of Skype. The round included participation from James McClave, Dustin Moskovitz, the Center for Emerging Risk Research, Eric Schmidt, and others.To find out more about Anthropic\u2019s research agenda and approach, you can read our website and its job postings. The company is hiring researchers, engineers, and operational experts to support it in executing against its research roadmap. Find out more here: Anthropic.com."
    }
  ]
}